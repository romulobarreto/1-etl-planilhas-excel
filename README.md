# 1-ETL-PLANILHAS-EXCEL üìäüìÅ

Projeto de estudo de Engenharia de Dados focado em **ETL de m√∫ltiplas planilhas Excel**.

A ideia √© pegar ~50 arquivos `.xlsx` de entrada, consolidar tudo em um conjunto √∫nico e, ao mesmo tempo, aplicar boas pr√°ticas de:

- organiza√ß√£o de projeto
- gerenciamento de depend√™ncias com **Poetry**
- uso de **pyenv**
- padr√µes de c√≥digo (blue + isort)
- testes automatizados com **pytest**
- automa√ß√µes com **taskipy** e **pre-commit**
- documenta√ß√£o com **MkDocs** (com tema **mkdocs-material**)

---

## üéØ Objetivos do Projeto

- Praticar a **estrutura√ß√£o completa** de um projeto de dados do zero.
- Implementar um **pipeline ETL** simples, mas bem organizado.
- Usar ferramentas que s√£o comuns no dia a dia de um engenheiro de dados.
- Servir como **projeto 1** da minha jornada em engenharia de dados, registrando a evolu√ß√£o no GitHub.

---

## üß± Arquitetura / Estrutura de Pastas

Estrutura geral do projeto (simplificada):

```bash
1-etl-planilhas-excel/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/      # ~50 arquivos Excel de entrada
‚îÇ   ‚îî‚îÄ‚îÄ output/     # arquivos consolidados gerados pelo ETL
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ 1_etl_planilhas_excel/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ main.py        # ponto de entrada do pipeline
‚îÇ       ‚îú‚îÄ‚îÄ extract.py     # fun√ß√µes de extra√ß√£o (ler os Excels)
‚îÇ       ‚îú‚îÄ‚îÄ transform.py   # fun√ß√µes de limpeza e transforma√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ load.py        # fun√ß√µes de carga (salvar o resultado)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .python-version
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ README.md
```

---

## üîß Tecnologias e Ferramentas

- **Python** (gerenciado com `pyenv`)
- **Poetry** para gerenciamento de depend√™ncias e virtualenv
- **Pandas** (para manipula√ß√£o das planilhas Excel) ‚Äì a ser adicionado
- **Pytest** para testes automatizados ‚Äì a ser configurado
- **Blue** para formata√ß√£o de c√≥digo
- **isort** para organiza√ß√£o de imports
- **Taskipy** para criar tarefas de automa√ß√£o
  (`task test`, `task lint`, `task format`, `task run`, etc.) ‚Äì a ser configurado
- **Pre-commit** para rodar checagens autom√°ticas antes dos commits ‚Äì a ser configurado
- **MkDocs** + **mkdocs-material** para documenta√ß√£o do projeto ‚Äì a ser configurado

---

## üöÄ Como rodar o projeto (vis√£o geral)

> Esses passos s√£o um guia geral. Os comandos exatos podem variar de acordo com o ambiente, mas a ideia √© essa:

1. **Clonar o reposit√≥rio**
2. **Definir a vers√£o do Python** com `pyenv` (por ex.: `3.14.0`).
3. **Criar/usar o ambiente virtual** com o Poetry.
4. **Instalar as depend√™ncias** definidas no `pyproject.toml`.
5. Colocar os arquivos Excel na pasta `data/input/`.
6. Rodar o script principal (por exemplo, o m√≥dulo `main` do pacote) para executar o ETL.

Conforme o projeto evoluir, esta se√ß√£o ser√° atualizada com os comandos exatos.

---

## üß¨ Desenho do ETL (alto n√≠vel)

O pipeline segue a cl√°ssica divis√£o **Extract ‚Üí Transform ‚Üí Load**:

1. **Extract (`extract.py`)**
   - Ler todos os arquivos Excel em `data/input/`.
   - Padronizar colunas b√°sicas (nomes, tipos etc.).

2. **Transform (`transform.py`)**
   - Limpar dados (valores nulos, tipos incorretos, etc.).
   - Padronizar formatos (datas, n√∫meros, categorias).
   - Unir as tabelas em um √∫nico DataFrame consolidado.

3. **Load (`load.py`)**
   - Salvar o resultado consolidado em `data/output/`.
   - Formatos poss√≠veis: `.csv`, `.parquet` ou `.xlsx` consolidado.

4. **Orquestra√ß√£o (`main.py`)**
   - Ponto de entrada que chama `extract`, depois `transform`, depois `load`.

---

## üß™ Testes

Os testes ser√£o escritos usando **pytest**. A ideia √©:

- testar fun√ß√µes individuais de extra√ß√£o, transforma√ß√£o e carga;
- garantir que o pipeline funciona mesmo se a estrutura de arquivos mudar um pouco;
- facilitar refatora√ß√µes futuras sem medo.

No in√≠cio, os testes ser√£o simples (ex.: testar se a fun√ß√£o consegue ler 1 planilha exemplo). Conforme o projeto evoluir, os testes ficam mais completos.

---

## üßπ Padr√µes de C√≥digo

Este projeto vai usar principalmente:

- **Blue** para formata√ß√£o autom√°tica do c√≥digo;
- **isort** para organizar imports.

A ideia √© automatizar isso via:

- **taskipy** (tarefas como `task format` e `task lint`);
- **pre-commit** (para rodar essas checagens antes dos commits).

Assim, o foco fica na l√≥gica de dados, e n√£o em brigar com estilo de c√≥digo.

---

## üìö Documenta√ß√£o (MkDocs)

A documenta√ß√£o deste projeto ser√° constru√≠da usando **MkDocs**, com o tema **mkdocs-material**.

A ideia √© ter:

- uma vis√£o geral do projeto e do pipeline ETL;
- explica√ß√£o das fun√ß√µes principais (`extract`, `transform`, `load`, `main`);
- exemplos de uso;
- instru√ß√µes de instala√ß√£o e execu√ß√£o mais detalhadas.

A estrutura planejada √© algo como:

- `docs/`
  - `index.md` ‚Äî p√°gina inicial da documenta√ß√£o
  - `etl.md` ‚Äî detalhes do pipeline de ETL
  - `setup.md` ‚Äî guia de instala√ß√£o e configura√ß√£o do ambiente
  - `faq.md` ‚Äî d√∫vidas frequentes (opcional)

No futuro, a documenta√ß√£o poder√° ser publicada usando **GitHub Pages**, permitindo acessar tudo via navegador.

---

## ‚úÖ Status do Projeto

- [x] Estrutura inicial do projeto criada
- [x] Organiza√ß√£o das pastas (`src`, `tests`, `data`)
- [ ] Configura√ß√£o completa do `pyproject.toml` (depend√™ncias)
- [ ] Implementa√ß√£o do ETL (extract/transform/load)
- [ ] Testes automatizados com pytest
- [ ] Taskipy + pre-commit configurados
- [ ] Documenta√ß√£o com MkDocs (estrutura e publica√ß√£o)

Este README ser√° atualizado conforme cada etapa for conclu√≠da.

---

## üí¨ Sobre o autor

Projeto criado para estudos por **R√¥mulo**, como parte da jornada para se tornar **Engenheiro de Dados**, inspirado no workshop *"Como Estruturar um Projeto de Dados do Zero"* do curso **Jornada de Dados**.

Sinta-se √† vontade para abrir issues/sugest√µes ou apenas usar este reposit√≥rio como refer√™ncia de estudo.
